{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define our genetic algorithm mapper with the following algorithm. For our algorithm, we use the following definition of fitness.\n",
    "fitness = 1 / (latency  energy)\n",
    "n = 5, k = 20, p = 10\n",
    "\n",
    "1. Generate n = 5 randomly ordered strings of the valid dataflow, that is a random permutation of [R, S, P, Q, C, M, N]. Initialize f to 0.\n",
    "2. Initialize a goal fitness g, dependent on latency and energy.\n",
    "3. While f>g,\n",
    "    Mutation: For i from 1 to n mutations, mutate each permutation k/n times to get k mutations. For each mutation, pick two parameters at random and swap them.\n",
    "    Selection: Calculate latency and energy and evaluate the fitness of each k mutations. Take the p = 10 with the highest fitness.\n",
    "    Crossover: Take pairs of p = 10 mutations and crossover to get n = 5 permutations. Let f = top fitness from these permutations.\n",
    "4. Return best permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from loaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(dataflow, workload):\n",
    "    # return random.randint(1, 1000)\n",
    "    data = evaluate(dataflow, workload)\n",
    "    energy, latency = data\n",
    "    inverse_EDP = 1 / (energy * latency)\n",
    "    print(f\"{dataflow} has a fitness of {inverse_EDP}\")\n",
    "    return inverse_EDP\n",
    "\n",
    "\n",
    "def evaluate(dataflow, workload):\n",
    "    '''\n",
    "    Evaluates the given dataflow on -- architecture\n",
    "\n",
    "    dataflow: computation ordering in list format\n",
    "    workload: the file path to the workload this is being evaluated on\n",
    "    returns tuple of energy, latency\n",
    "    '''\n",
    "    # dataflow = dataflow.split()\n",
    "    print(\"evaluating\")\n",
    "    \n",
    "    arch_config = dict( # TODO: need to set this to out config\n",
    "        DRAM_factor_N=50,\n",
    "        DRAM_factor_M=8,\n",
    "        DRAM_factor_C=4,\n",
    "        global_buffer_factor_N=1,\n",
    "        global_buffer_factor_M=1,\n",
    "        global_buffer_factor_C=1,\n",
    "        PE_spatial_factor_M=1,\n",
    "        PE_spatial_factor_C=1,\n",
    "        scratchpad_factor_N=1,\n",
    "    )\n",
    "    \n",
    "    config = { **arch_config, \"pe_meshX\": 1, \"pe_meshY\": 16 } # TODO replace the pe mesh values\n",
    "    #TODO write the permutation in designs/system/map.yaml to dataflow\n",
    "    \n",
    "    THRES = (float('inf'), float('inf')) # TODO ?? \n",
    "    \n",
    "    min_energy = float('inf')\n",
    "    # for i, k in enumerate(to_run):\n",
    "    cycle_thres, energy_thres = THRES # TODO whats our threshold\n",
    "    result = run_timeloop_model(\n",
    "        config,\n",
    "        architecture='designs/system/arch.yaml',\n",
    "        mapping='designs/system/map.yaml',\n",
    "        problem=workload #'layer_shapes/conv2.yaml'\n",
    "    )\n",
    "    stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "    mapping = result.mapping\n",
    "    # print(stats)\n",
    "\n",
    "    lines = stats.split('\\n')\n",
    "    energy = float([l for l in lines if 'Energy:' in l][0].split(' ', 2)[1])\n",
    "    cycles = int([l for l in lines if 'Cycles:' in l][0].split(' ', 1)[1])\n",
    "    min_energy = min(min_energy, energy)\n",
    "\n",
    "    print(min_energy, cycles)\n",
    "    return min_energy, cycles\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "evaluating\n",
      "[INFO] 2025-04-27 19:43:08,488 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657.11 31360000\n",
      "['M', 'Q', 'S', 'P', 'C', 'N', 'R'] has a fitness of 4.8527271084051096e-11\n",
      "evaluating\n",
      "[INFO] 2025-04-27 19:43:10,796 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657.11 31360000\n",
      "['M', 'Q', 'S', 'C', 'P', 'R', 'N'] has a fitness of 4.8527271084051096e-11\n",
      "evaluating\n",
      "[INFO] 2025-04-27 19:43:13,023 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657.11 31360000\n",
      "['P', 'Q', 'N', 'M', 'R', 'C', 'S'] has a fitness of 4.8527271084051096e-11\n",
      "evaluating\n",
      "[INFO] 2025-04-27 19:43:15,307 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657.11 31360000\n",
      "['M', 'R', 'C', 'Q', 'N', 'S', 'P'] has a fitness of 4.8527271084051096e-11\n",
      "evaluating\n",
      "[INFO] 2025-04-27 19:43:17,573 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657.11 31360000\n",
      "['C', 'Q', 'R', 'N', 'S', 'M', 'P'] has a fitness of 4.8527271084051096e-11\n",
      "selection\n",
      "evaluating\n",
      "[INFO] 2025-04-27 19:43:19,820 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657.11 31360000\n",
      "['M', 'Q', 'S', 'C', 'P', 'N', 'R'] has a fitness of 4.8527271084051096e-11\n",
      "evaluating\n",
      "[INFO] 2025-04-27 19:43:22,118 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Selection\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m mutations_fitnesses \u001b[38;5;241m=\u001b[39m [[mutation, fitness(mutation, workload)] \u001b[38;5;28;01mfor\u001b[39;00m mutation \u001b[38;5;129;01min\u001b[39;00m mutations]\n\u001b[1;32m     35\u001b[0m mutations_fitnesses\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# high to low fitness\u001b[39;00m\n\u001b[1;32m     36\u001b[0m selections_fitnesses \u001b[38;5;241m=\u001b[39m mutations_fitnesses[:p] \n",
      "Cell \u001b[0;32mIn[25], line 34\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Selection\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m mutations_fitnesses \u001b[38;5;241m=\u001b[39m [[mutation, \u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmutation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkload\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m mutation \u001b[38;5;129;01min\u001b[39;00m mutations]\n\u001b[1;32m     35\u001b[0m mutations_fitnesses\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# high to low fitness\u001b[39;00m\n\u001b[1;32m     36\u001b[0m selections_fitnesses \u001b[38;5;241m=\u001b[39m mutations_fitnesses[:p] \n",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m, in \u001b[0;36mfitness\u001b[0;34m(dataflow, workload)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfitness\u001b[39m(dataflow, workload):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# return random.randint(1, 1000)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     energy, latency \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      5\u001b[0m     inverse_EDP \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (energy \u001b[38;5;241m*\u001b[39m latency)\n",
      "Cell \u001b[0;32mIn[24], line 41\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataflow, workload)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# for i, k in enumerate(to_run):\u001b[39;00m\n\u001b[1;32m     40\u001b[0m cycle_thres, energy_thres \u001b[38;5;241m=\u001b[39m THRES \u001b[38;5;66;03m# TODO whats our threshold\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_timeloop_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43marchitecture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesigns/system/arch.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesigns/system/map.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkload\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#'layer_shapes/conv2.yaml'\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output_dir/timeloop-model.stats.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     48\u001b[0m mapping \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmapping\n",
      "File \u001b[0;32m~/loaders.py:51\u001b[0m, in \u001b[0;36mrun_timeloop_model\u001b[0;34m(jinja_parse_data, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m spec \u001b[38;5;241m=\u001b[39m tl\u001b[38;5;241m.\u001b[39mSpecification\u001b[38;5;241m.\u001b[39mfrom_yaml_files(\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesigns/top.yaml.jinja2\u001b[39m\u001b[38;5;124m\"\u001b[39m, jinja_parse_data\u001b[38;5;241m=\u001b[39mjinja_parse_data\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m spec\u001b[38;5;241m.\u001b[39mERT \u001b[38;5;241m=\u001b[39m Ert(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDictNode\u001b[38;5;241m.\u001b[39mfrom_yaml_files(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dir/ERT.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERT\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 51\u001b[0m spec\u001b[38;5;241m.\u001b[39mART \u001b[38;5;241m=\u001b[39m Art(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mDictNode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_yaml_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_dir/ART.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mART\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# print(spec)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# app = tl.to_model_app(spec, output_dir=\"./output_dir\")\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# print('Model app created')\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tl\u001b[38;5;241m.\u001b[39mcall_model(spec, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/nodes.py:1342\u001b[0m, in \u001b[0;36mDictNode.from_yaml_files\u001b[0;34m(cls, jinja_parse_data, *files, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1339\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not end with .yaml, .jinja, or .jinja2. Skipping.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1340\u001b[0m     )\n\u001b[1;32m   1341\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading yaml file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, f)\n\u001b[0;32m-> 1342\u001b[0m loaded \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjinja_parse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loaded, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a dictionary from file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(loaded)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1346\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelergy/utils/yaml.py:365\u001b[0m, in \u001b[0;36mload_yaml\u001b[0;34m(path, data, include_dirs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading YAML file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 365\u001b[0m     result \u001b[38;5;241m=\u001b[39m merge_check(\u001b[43mget_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    366\u001b[0m     parse_globals_key(result, path, include_dirs)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/main.py:451\u001b[0m, in \u001b[0;36mYAML.load\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    449\u001b[0m constructor, parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_constructor_parser(stream)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     parser\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/constructor.py:114\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomposer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/composer.py:67\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_single_node\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Drop the STREAM-START event.\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Compose a document if the stream is not empty.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     document: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/parser.py:161\u001b[0m, in \u001b[0;36mParser.get_event\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# assert self.current_event is not None\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# if self.current_event.end_mark.line != self.peek_event().start_mark.line:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m xprintf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_event\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeek_event()\u001b[38;5;241m.\u001b[39mstart_mark\u001b[38;5;241m.\u001b[39mline)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/parser.py:177\u001b[0m, in \u001b[0;36mParser.parse_stream_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_stream_start\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Parse the stream start.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscanner\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_token_comment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     event \u001b[38;5;241m=\u001b[39m StreamStartEvent(token\u001b[38;5;241m.\u001b[39mstart_mark, token\u001b[38;5;241m.\u001b[39mend_mark, encoding\u001b[38;5;241m=\u001b[39mtoken\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# Prepare the next state.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/parser.py:815\u001b[0m, in \u001b[0;36mRoundTripParser.move_token_comment\u001b[0;34m(self, token, nt, empty)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmove_token_comment\u001b[39m(\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28mself\u001b[39m, token: Any, nt: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, empty: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    814\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 815\u001b[0m     token\u001b[38;5;241m.\u001b[39mmove_old_comment(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscanner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeek_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m nt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m nt, empty\u001b[38;5;241m=\u001b[39mempty)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/scanner.py:1747\u001b[0m, in \u001b[0;36mRoundTripScanner.peek_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpeek_token\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;66;03m# Return the next token, but do not delete if from the queue.\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_more_tokens():\n\u001b[0;32m-> 1747\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_more_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1748\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_comments()\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/scanner.py:278\u001b[0m, in \u001b[0;36mScanner.fetch_more_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Is it the value indicator?\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_value():\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Is it an alias?\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/scanner.py:611\u001b[0m, in \u001b[0;36mScanner.fetch_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_level:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_indent(key\u001b[38;5;241m.\u001b[39mcolumn):\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m    610\u001b[0m             key\u001b[38;5;241m.\u001b[39mtoken_number \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens_taken,\n\u001b[0;32m--> 611\u001b[0m             \u001b[43mBlockMappingStartToken\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmark\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    612\u001b[0m         )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;66;03m# There cannot be two simple keys one after another.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_simple_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ruamel/yaml/tokens.py:16\u001b[0m, in \u001b[0;36mToken.__init__\u001b[0;34m(self, start_mark, end_mark)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mToken\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;18m__slots__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_mark\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_mark\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_comment\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_mark: StreamMark, end_mark: StreamMark) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_mark \u001b[38;5;241m=\u001b[39m start_mark\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_mark \u001b[38;5;241m=\u001b[39m end_mark\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# convolution\n",
    "dataflow = ['R', 'S', 'P', 'Q', 'C', 'M', 'N']\n",
    "workload = 'layer_shapes/conv2.yaml'\n",
    "\n",
    "# n population -> k mutations -> p selection -> n population\n",
    "# constraints: n | k, p/2 = n\n",
    "n = 5\n",
    "k = 20\n",
    "p = 10\n",
    "\n",
    "# Generate n base permutations\n",
    "population = [random.sample(dataflow, len(dataflow)) for i in range(n)]\n",
    "\n",
    "print(\"Initializing\")\n",
    "# Initialize base fitness and goal fitness\n",
    "dfs_fitnesses = [[df, fitness(df, workload)] for df in population]\n",
    "best_df, f = max(dfs_fitnesses, key=lambda x: x[1])\n",
    "g = 1000  # if terminating using goal fitness\n",
    "iter = 10  # if terminating using timeout\n",
    "\n",
    "for i in range(iter):\n",
    "    # Mutation\n",
    "    mutations = []  # len(mutations) = k\n",
    "    for df in population:\n",
    "        for m in range(k):\n",
    "            mutation = df.copy()\n",
    "            # swap two random indices\n",
    "            idx1, idx2 = random.sample(range(len(dataflow)), 2)\n",
    "            mutation[idx1], mutation[idx2] = mutation[idx2], mutation[idx1]\n",
    "            mutations.append(mutation)\n",
    "    \n",
    "    # Selection\n",
    "    print(\"selection\")\n",
    "    mutations_fitnesses = [[mutation, fitness(mutation, workload)] for mutation in mutations]\n",
    "    mutations_fitnesses.sort(key=lambda x: x[1], reverse=True) # high to low fitness\n",
    "    selections_fitnesses = mutations_fitnesses[:p] \n",
    "    selections = [x[0] for x in selections_fitnesses] # len(selections) = p\n",
    "\n",
    "    # Crossover\n",
    "    print(\"crossover\")\n",
    "    random.shuffle(selections)\n",
    "    crossover_pairs = [(selections[i], selections[i+1]) for i in range(0, len(selections), 2)]\n",
    "    crossovers = []  # len(crossovers) = n\n",
    "    for pair in crossover_pairs:\n",
    "        s1, s2 = pair\n",
    "        cut_point = random.randint(1, len(s1) - 1)\n",
    "        first_half = s1[:cut_point]\n",
    "        second_half = s2.copy()\n",
    "        for parameter in first_half:\n",
    "            second_half.remove(parameter)\n",
    "        crossover = first_half + second_half\n",
    "        crossovers.append(crossover)\n",
    "\n",
    "    crossovers_fitnesses = [[crossover, fitness(crossover, workload)] for crossover in crossovers]\n",
    "    best_df_trial, f_trial = max(crossovers_fitnesses, key=lambda x: x[1])\n",
    "    if f_trial > f:\n",
    "        best_df, f = best_df_trial, f_trial\n",
    "    if f >= g:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
