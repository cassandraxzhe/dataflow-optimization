{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define our genetic algorithm mapper with the following algorithm. For our algorithm, we use the following definition of fitness.\n",
    "fitness = 1 / (latency  energy)\n",
    "n = 5, k = 20, p = 10\n",
    "\n",
    "1. Generate n = 5 randomly ordered strings of the valid dataflow, that is a random permutation of [R, S, P, Q, C, M, N]. Initialize f to 0.\n",
    "2. Initialize a goal fitness g, dependent on latency and energy.\n",
    "3. While f>g,\n",
    "    Mutation: For i from 1 to n mutations, mutate each permutation k/n times to get k mutations. For each mutation, pick two parameters at random and swap them.\n",
    "    Selection: Calculate latency and energy and evaluate the fitness of each k mutations. Take the p = 10 with the highest fitness.\n",
    "    Crossover: Take pairs of p = 10 mutations and crossover to get n = 5 permutations. Let f = top fitness from these permutations.\n",
    "4. Return best permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from loaders import *\n",
    "import yaml\n",
    "from yaml import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraints:\n",
      "  version: 0.4\n",
      "  targets:\n",
      "  - target: DRAM\n",
      "    type: dataspace\n",
      "    keep: [Inputs, Outputs, Weights]\n",
      "    bypass: []\n",
      "  - target: DRAM\n",
      "    type: temporal\n",
      "    permutation: [R, S, Q, P, C, M, N]\n",
      "  - target: global_buffer\n",
      "    type: dataspace\n",
      "    keep: [Inputs, Outputs, Weights]\n",
      "    bypass: []\n",
      "  - target: global_buffer\n",
      "    type: temporal\n",
      "    permutation: [S, R, Q, P, C, M, N]\n",
      "  - target: PE\n",
      "    type: spatial\n",
      "    permutation: [C, M, R, S, P, Q, N]\n",
      "    split: 1\n",
      "  - target: scratchpad\n",
      "    type: dataspace\n",
      "    keep: [Weights]\n",
      "    bypass: [Inputs, Outputs]\n",
      "  - target: scratchpad\n",
      "    type: temporal\n",
      "    permutation: [Q, P, N, C, M, S, R]\n",
      "\n",
      "  - target: weight_reg\n",
      "    type: dataspace\n",
      "    keep: [Weights]\n",
      "    bypass: [Inputs, Outputs]\n",
      "  - target: weight_reg\n",
      "    type: temporal\n",
      "    permutation: [R, S, P, Q, C, M, N]\n",
      "  - target: input_activation_reg\n",
      "    type: dataspace\n",
      "    keep: [Inputs]\n",
      "    bypass: [Weights, Outputs]\n",
      "  - target: input_activation_reg\n",
      "    type: temporal\n",
      "    permutation: [R, S, P, Q, C, M, N]\n",
      "  - target: output_activation_reg\n",
      "    type: dataspace\n",
      "    keep: [Outputs]\n",
      "    bypass: [Weights, Inputs]\n",
      "  - target: output_activation_reg\n",
      "    type: temporal\n",
      "    permutation: [R, S, P, Q, C, M, N]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_config('designs/system/constraints.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(dataflow, workload, pe_dims):\n",
    "    # return random.randint(1, 1000)\n",
    "    data = evaluate(dataflow, workload)\n",
    "    energy, latency = data\n",
    "    inverse_EDP = 1 / (energy * latency)\n",
    "    print(f\"{dataflow} has a fitness of {inverse_EDP}\")\n",
    "    return inverse_EDP\n",
    "\n",
    "\n",
    "def evaluate(dataflow, workload):\n",
    "    '''\n",
    "    Evaluates the given dataflow on -- architecture\n",
    "\n",
    "    dataflow: computation ordering in list format\n",
    "    workload: the file path to the workload this is being evaluated on\n",
    "    returns tuple of energy, latency\n",
    "    '''\n",
    "    \n",
    "    mapper = 'designs/_include/mapper.yaml'\n",
    "    constraints = 'designs/system/constraints.yaml'\n",
    "\n",
    "    # create a new constraints file with the new PE permutation\n",
    "    stream = open(constraints, 'r')\n",
    "    dictionary = yaml.safe_load(stream)\n",
    "    # print(dictionary['constraints']['targets'][4])\n",
    "    idx = 4 # PE\n",
    "    dictionary['constraints']['targets'][idx]['permutation'] = dataflow\n",
    "\n",
    "        \n",
    "    filename = ''.join(dataflow)\n",
    "    with open(f'iters/configs/{filename}.yaml', 'w') as file:\n",
    "        yaml.dump(dictionary, file, default_flow_style=False)\n",
    "\n",
    "    constraints = f'iters/configs/{filename}.yaml'\n",
    "\n",
    "    sys_1x16_result = run_timeloop_mapper( # TODO: this should be run_timeloop_mapper not run_timeloop_model!\n",
    "        # config,\n",
    "        pe_dims,\n",
    "        architecture='designs/system/arch.yaml',\n",
    "        mapper=mapper,\n",
    "        problem=workload,\n",
    "        constraints=constraints \n",
    "    )\n",
    "    \n",
    "    # print('done running mapper')\n",
    "    stats = open('./output_dir/timeloop-mapper.stats.txt', 'r').read()\n",
    "    mapping = sys_1x16_result.mapping\n",
    "    # print(stats)\n",
    "    # print(sys_1x16_result.energy, sys_1x16_result.cycles)\n",
    "    # print(mapping)\n",
    "\n",
    "    lines = stats.split('\\n')\n",
    "    energy = float([l for l in lines if 'Energy:' in l][0].split(' ', 2)[1])\n",
    "    cycles = int([l for l in lines if 'Cycles:' in l][0].split(' ', 1)[1])\n",
    "    # min_energy = min(min_energy, energy)\n",
    "\n",
    "    print(energy, cycles)\n",
    "    return energy, cycles\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "[INFO] 2025-05-02 00:01:45,352 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    }
   ],
   "source": [
    "# TODO: I'm OOPing this shit later\n",
    "# and adding a mapper_call_count field\n",
    "def mutation(population):\n",
    "    \"\"\"\n",
    "    Performs a random swap mutation for every member of `population`.\n",
    "    Returns a list of the new mutated population.\n",
    "    \"\"\"\n",
    "    mutations = []\n",
    "\n",
    "    for df in population:\n",
    "        for _ in range(k):\n",
    "            mutation = df.copy()\n",
    "            # swap two random indices\n",
    "            idx1, idx2 = random.sample(range(len(dataflow)), 2)\n",
    "            mutation[idx1], mutation[idx2] = mutation[idx2], mutation[idx1]\n",
    "            mutations.append(mutation)\n",
    "    return mutations\n",
    "\n",
    "\n",
    "def selection(population: list[str], p: int, fitness, workload: str, pe_dims):\n",
    "    \"\"\"\n",
    "    Evaluates the fitness using `fitness` func of all members of a population on\n",
    "    `workload` workload with pe dimensions `pe_dims`, and performs selection of \n",
    "    the top p candidates.\n",
    "    \"\"\"\n",
    "    print(\"selection\")\n",
    "    fitnesses = []\n",
    "    for candidate in population:\n",
    "        # do a check to see if we've already run this config\n",
    "        if ''.join(candidate) in VISITED:\n",
    "            print('already visited' + ''.join(candidate))\n",
    "            fitnesses.append([candidate, VISITED[''.join(candidate)]])\n",
    "        else:\n",
    "            fitnesses.append([candidate, fitness(candidate, workload, pe_dims)])\n",
    "    # fitnesses = [[candidate, fitness(candidate, workload, pe_dims)] for candidate in population]\n",
    "    # fitnesses = { ''.join(candidate) : fitness(candidate, workload, pe_dims) for candidate in population }\n",
    "    print(f'fitnesses: {fitnesses}')\n",
    "    fitnesses.sort(key=lambda x: x[1], reverse=True) # high to low fitness\n",
    "    print(f'sorted fitnesses: {fitnesses}')\n",
    "    selections = fitnesses[:p] \n",
    "    print(f'3')\n",
    "    selections = [x[0] for x in selections] # len(selections) = p\n",
    "    # print(f'selections: {selections}')\n",
    "    return selections\n",
    "\n",
    "# convolution\n",
    "dataflow = ['R', 'S', 'P', 'Q', 'C', 'M', 'N']\n",
    "# workload = 'layer_shapes/conv2.yaml'\n",
    "# workload = 'layer_shapes/conv1.yaml'\n",
    "\n",
    "workload = 'layer_shapes/fc1.yaml'\n",
    "# pe_dims = {'pe_meshX': 1, 'pe_meshY': 16}\n",
    "pe_dims = {'pe_meshX': 2, 'pe_meshY': 8}\n",
    "# pe_dims = {'pe_meshX': 4, 'pe_meshY': 4}\n",
    "\n",
    "# n population -> k mutations -> p selection -> n population\n",
    "# constraints: n | k, p/2 = n\n",
    "n = 5\n",
    "k = 20\n",
    "p = 10\n",
    "\n",
    "# Generate n base permutations\n",
    "population = [random.sample(dataflow, len(dataflow)) for _ in range(n)]\n",
    "\n",
    "print(\"Initializing\")\n",
    "# Initialize base fitness and goal fitness\n",
    "dfs_fitnesses = [[df, fitness(df, workload, pe_dims)] for df in population]\n",
    "best_df, f = max(dfs_fitnesses, key=lambda x: x[1])\n",
    "g = 1000  # if terminating using goal fitness\n",
    "iter = 10  # if terminating using timeout\n",
    "# visited = {''.join(df) for df in population}\n",
    "VISITED = { ''.join(df) : fitness(df, workload, pe_dims) for df in population }\n",
    "\n",
    "\n",
    "# TODO: include condition to check if a permutation has already been tested\n",
    "# TODO: why aren't we reaching crossover print statement?\n",
    "# TODO: why isn't the best fitness from initial population being chosen? \n",
    "\n",
    "\n",
    "# def genetic_algorithm(): TODO: make this a func\n",
    "for i in range(iter):\n",
    "    print(\"\\nITERATION: \", i)\n",
    "    # Mutation\n",
    "    mutations = mutation(population)\n",
    "    print(mutations)\n",
    "    \n",
    "    # Selection\n",
    "    selections = selection(mutations, p, fitness, workload, pe_dims)\n",
    "    # print(\"selection\")\n",
    "    # mutations_fitnesses = [[mutation, fitness(mutation, workload, pe_dims)] for mutation in mutations]\n",
    "    # print(f'mutations_fitnesses: {mutations_fitnesses}')\n",
    "    # mutations_fitnesses.sort(key=lambda x: x[1], reverse=True) # high to low fitness\n",
    "    # print('2')\n",
    "    # selections_fitnesses = mutations_fitnesses[:p] \n",
    "    # print('3')\n",
    "    # selections = [x[0] for x in selections_fitnesses] # len(selections) = p\n",
    "    print(f'selections done running: {selections}')\n",
    "\n",
    "    # Crossover\n",
    "    print(\"crossover\")\n",
    "    random.shuffle(selections)\n",
    "    crossover_pairs = [(selections[i], selections[i+1]) for i in range(0, len(selections), 2)]\n",
    "    crossovers = []  # len(crossovers) = n\n",
    "    for pair in crossover_pairs:\n",
    "        s1, s2 = pair\n",
    "        cut_point = random.randint(1, len(s1) - 1)\n",
    "        first_half = s1[:cut_point]\n",
    "        second_half = s2.copy()\n",
    "        for parameter in first_half:\n",
    "            second_half.remove(parameter)\n",
    "        crossover = first_half + second_half\n",
    "        crossovers.append(crossover)\n",
    "\n",
    "    crossovers_fitnesses = [[crossover, fitness(crossover, workload, pe_dims)] for crossover in crossovers]\n",
    "    best_df_trial, f_trial = max(crossovers_fitnesses, key=lambda x: x[1])\n",
    "    if f_trial > f:\n",
    "        best_df, f = best_df_trial, f_trial\n",
    "    if f >= g:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
